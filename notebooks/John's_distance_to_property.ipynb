{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find proximity to school using Openroute Service API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing proximity complete and data saved to property_school.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from geopy.distance import geodesic\n",
    "from pathlib import Path\n",
    "import time\n",
    "import logging\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='process_log.log', level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Load the property and school data\n",
    "school_df = pd.read_csv(Path.cwd().parent / 'data' / 'curated' / 'school_location_cleaned_2023.csv')\n",
    "property_df = pd.read_csv(Path.cwd().parent / 'data' / 'curated' / 'rent_cleaned.csv')\n",
    "\n",
    "# Drop rows with null entries in school_df and property_df\n",
    "school_df = school_df.dropna(subset=['latitude', 'longitude'])\n",
    "property_df = property_df.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# Split property_df into 5 partitions, each with 600 entries (last one may have less)\n",
    "partitions = [property_df[i:i+600] for i in range(0, len(property_df), 600)]\n",
    "\n",
    "# Define 5 different API keys\n",
    "api_keys = [\n",
    "    '5b3ce3597851110001cf62484aef543442ec490dbaf2a41a693499c4',\n",
    "    '5b3ce3597851110001cf624892918ea9d1e9424cbe679f4d70ca1324',\n",
    "    '5b3ce3597851110001cf6248f21e786bb58c4a5b8aa0988c6e26ba3e',\n",
    "    '5b3ce3597851110001cf62487ac82fa019bf422fa327134f28f2a197',\n",
    "    '5b3ce3597851110001cf62487ec54a381ceb450388b047637d95f3bb'\n",
    "]\n",
    "\n",
    "# Define the top_3_nearest function to calculate the nearest schools\n",
    "def top_3_nearest(latitude, longitude, location_df):\n",
    "    def calculate_distance(row):\n",
    "        if pd.isna(row['latitude']) or pd.isna(row['longitude']):\n",
    "            return float('inf')\n",
    "        return geodesic((latitude, longitude), (row['latitude'], row['longitude'])).kilometers\n",
    "    \n",
    "    location_df['distance'] = location_df.apply(calculate_distance, axis=1)\n",
    "    return location_df.sort_values(by='distance').head(3)\n",
    "\n",
    "# Setup requests session with retry strategy\n",
    "def create_session_with_retries():\n",
    "    session = requests.Session()\n",
    "    retries = Retry(total=5,  # Total retries before giving up\n",
    "                    backoff_factor=1,  # Wait 1, 2, 4, 8, ... seconds between retries\n",
    "                    status_forcelist=[429, 500, 502, 503, 504],  # Retry on these status codes\n",
    "                    raise_on_status=False)  # Don't raise on error status codes\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "    return session\n",
    "\n",
    "# Function to process one partition of properties with progress tracking\n",
    "def process_partition(property_df_partition, api_key, partition_index, session):\n",
    "    property_df_partition['time_to_nearest_school(min)'] = None\n",
    "    property_df_partition['distance_to_nearest_school(km)'] = None\n",
    "    \n",
    "    total_rows = len(property_df_partition)  # Total number of rows to process\n",
    "    for local_index, (index, row) in enumerate(property_df_partition.iterrows(), start=1):  # local_index starts from 1\n",
    "        if pd.isna(row['latitude']) or pd.isna(row['longitude']):\n",
    "            logging.warning(f\"Skipping row {index} in partition {partition_index} due to missing latitude or longitude\")\n",
    "            continue\n",
    "        \n",
    "        top_schools = top_3_nearest(row['latitude'], row['longitude'], school_df)\n",
    "        \n",
    "        min_duration = float('inf')\n",
    "        min_distance = float('inf')\n",
    "        \n",
    "        for _, school in top_schools.iterrows():\n",
    "            start = f\"{row['longitude']},{row['latitude']}\"\n",
    "            end = f\"{school['longitude']},{school['latitude']}\"\n",
    "            api_url = f\"https://api.openrouteservice.org/v2/directions/driving-car?api_key={api_key}&start={start}&end={end}\"\n",
    "            \n",
    "            try:\n",
    "                response = session.get(api_url, headers={'Accept': 'application/json, application/geo+json, application/gpx+xml, img/png; charset=utf-8'})\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "                travel_info = data['features'][0]['properties']['segments'][0]\n",
    "                duration = travel_info['duration'] / 60  # Convert from seconds to minutes\n",
    "                distance = travel_info['distance'] / 1000  # Convert from meters to kilometers\n",
    "\n",
    "                if duration < min_duration:\n",
    "                    min_duration = duration\n",
    "                    min_distance = distance\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                logging.error(f\"Error on row {index} in partition {partition_index}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            time.sleep(1.51)\n",
    "        \n",
    "        # Record the nearest travel time and distance\n",
    "        property_df_partition.at[index, 'time_to_nearest_school(min)'] = min_duration\n",
    "        property_df_partition.at[index, 'distance_to_nearest_school(km)'] = min_distance\n",
    "        \n",
    "        # Progress tracking: Show the current entry out of total for this partition\n",
    "        print(f\"Partition {partition_index}: Processing property {local_index}/{total_rows}\", end='\\r')\n",
    "\n",
    "    return property_df_partition\n",
    "\n",
    "# Process each partition with a different API key and track progress\n",
    "final_df = pd.DataFrame()\n",
    "session = create_session_with_retries()  # Create a session with retries\n",
    "\n",
    "for i, partition in enumerate(partitions):\n",
    "    logging.info(f\"Processing partition {i+1} with API key {i+1}\")\n",
    "    processed_partition = process_partition(partition.copy(), api_keys[i], i+1, session)\n",
    "    final_df = pd.concat([final_df, processed_partition])\n",
    "    logging.info(f\"Finished processing partition {i+1}\")\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "final_df.to_csv(Path.cwd().parent / 'data' / 'curated' / 'property_school.csv', index=False)\n",
    "\n",
    "logging.info(\"Processing complete and data saved to property_school.csv\")\n",
    "print(\"Processing proximity complete and data saved to property_school.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562\n"
     ]
    }
   ],
   "source": [
    "print(len(partitions[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the proximity to train station using open route service API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing proximity complete and data saved to property_train.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from geopy.distance import geodesic\n",
    "from pathlib import Path\n",
    "import time\n",
    "import logging\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='process_log_train.log', level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Load the property and train station data\n",
    "train_df = pd.read_csv(Path.cwd().parent / 'data' / 'curated' / 'train_station_cleaned.csv')\n",
    "property_df = pd.read_csv(Path.cwd().parent / 'data' / 'curated' / 'rent_cleaned.csv')\n",
    "\n",
    "# Drop rows with null entries in train_df and property_df\n",
    "train_df = train_df.dropna(subset=['latitude', 'longitude'])\n",
    "property_df = property_df.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# Split property_df into 5 partitions, each with 600 entries (last one may have less)\n",
    "partitions = [property_df[i:i+600] for i in range(0, len(property_df), 600)]\n",
    "\n",
    "# Define 5 different API keys\n",
    "api_keys = [\n",
    "    '5b3ce3597851110001cf6248b904653ba4ac4ed78f4ae7902e93a788',\n",
    "    '5b3ce3597851110001cf6248d679d4da97464cd5a0b5e369e3997ac2',\n",
    "    '5b3ce3597851110001cf6248afe6001af46b4b2d88a3918e49a74472',\n",
    "    '5b3ce3597851110001cf624851695d82a54b4cf583c8812c22d0bda5',\n",
    "    '5b3ce3597851110001cf62485b36bdcc87234532a9de9035fd611135'\n",
    "]\n",
    "\n",
    "# Define the top_3_nearest function to calculate the nearest train stations\n",
    "def top_3_nearest(latitude, longitude, location_df):\n",
    "    def calculate_distance(row):\n",
    "        if pd.isna(row['latitude']) or pd.isna(row['longitude']):\n",
    "            return float('inf')\n",
    "        return geodesic((latitude, longitude), (row['latitude'], row['longitude'])).kilometers\n",
    "    \n",
    "    location_df['distance'] = location_df.apply(calculate_distance, axis=1)\n",
    "    return location_df.sort_values(by='distance').head(3)\n",
    "\n",
    "# Setup requests session with retry strategy\n",
    "def create_session_with_retries():\n",
    "    session = requests.Session()\n",
    "    retries = Retry(total=5,  # Total retries before giving up\n",
    "                    backoff_factor=1,  # Wait 1, 2, 4, 8, ... seconds between retries\n",
    "                    status_forcelist=[429, 500, 502, 503, 504],  # Retry on these status codes\n",
    "                    raise_on_status=False)  # Don't raise on error status codes\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "    return session\n",
    "\n",
    "# Function to process one partition of properties with progress tracking\n",
    "def process_partition(property_df_partition, api_key, partition_index, session):\n",
    "    property_df_partition['time_to_nearest_train(min)'] = None\n",
    "    property_df_partition['distance_to_nearest_train(km)'] = None\n",
    "    \n",
    "    total_rows = len(property_df_partition)  # Total number of rows to process\n",
    "    for local_index, (index, row) in enumerate(property_df_partition.iterrows(), start=1):  # local_index starts from 1\n",
    "        if pd.isna(row['latitude']) or pd.isna(row['longitude']):\n",
    "            logging.warning(f\"Skipping row {index} in partition {partition_index} due to missing latitude or longitude\")\n",
    "            continue\n",
    "        \n",
    "        top_trains = top_3_nearest(row['latitude'], row['longitude'], train_df)\n",
    "        \n",
    "        min_duration = float('inf')\n",
    "        min_distance = float('inf')\n",
    "        \n",
    "        for _, train in top_trains.iterrows():\n",
    "            start = f\"{row['longitude']},{row['latitude']}\"\n",
    "            end = f\"{train['longitude']},{train['latitude']}\"\n",
    "            api_url = f\"https://api.openrouteservice.org/v2/directions/driving-car?api_key={api_key}&start={start}&end={end}\"\n",
    "            \n",
    "            try:\n",
    "                response = session.get(api_url, headers={'Accept': 'application/json, application/geo+json, application/gpx+xml, img/png; charset=utf-8'})\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "                travel_info = data['features'][0]['properties']['segments'][0]\n",
    "                duration = travel_info['duration'] / 60  # Convert from seconds to minutes\n",
    "                distance = travel_info['distance'] / 1000  # Convert from meters to kilometers\n",
    "\n",
    "                if duration < min_duration:\n",
    "                    min_duration = duration\n",
    "                    min_distance = distance\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                logging.error(f\"Error on row {index} in partition {partition_index}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            time.sleep(1.51)\n",
    "        \n",
    "        # Record the nearest travel time and distance\n",
    "        property_df_partition.at[index, 'time_to_nearest_train(min)'] = min_duration\n",
    "        property_df_partition.at[index, 'distance_to_nearest_train(km)'] = min_distance\n",
    "        \n",
    "        # Progress tracking: Show the current entry out of total for this partition\n",
    "        print(f\"Partition {partition_index}: Processing property {local_index}/{total_rows}\", end='\\r')\n",
    "\n",
    "    return property_df_partition\n",
    "\n",
    "# Process each partition with a different API key and track progress\n",
    "final_df = pd.DataFrame()\n",
    "session = create_session_with_retries()  # Create a session with retries\n",
    "\n",
    "for i, partition in enumerate(partitions):\n",
    "    logging.info(f\"Processing partition {i+1} with API key {i+1}\")\n",
    "    processed_partition = process_partition(partition.copy(), api_keys[i], i+1, session)\n",
    "    final_df = pd.concat([final_df, processed_partition])\n",
    "    logging.info(f\"Finished processing partition {i+1}\")\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "final_df.to_csv(Path.cwd().parent / 'data' / 'curated' / 'property_train.csv', index=False)\n",
    "\n",
    "logging.info(\"Processing complete and data saved to property_train.csv\")\n",
    "print(\"Processing proximity complete and data saved to property_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data with renamed columns saved to c:\\Users\\29557\\Documents\\GitHub\\project-2-group-real-estate-industry-project-7\\data\\curated\\rent_with_proximity.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the property_school and property_train data\n",
    "property_school_df = pd.read_csv(Path.cwd().parent / 'data' / 'curated' / 'property_school.csv')\n",
    "property_train_df = pd.read_csv(Path.cwd().parent / 'data' / 'curated' / 'property_train.csv')\n",
    "\n",
    "# Extract 'distance_to_nearest_school(km)' and 'time_to_nearest_school(min)' columns from property_school_df\n",
    "school_columns = property_school_df[['distance_to_nearest_school(km)', 'time_to_nearest_school(min)']]\n",
    "\n",
    "# Rename the 'time_to_nearest_train(min)' and 'distance_to_nearest_train(km)' columns in the property_train dataframe\n",
    "property_train_df.rename(columns={\n",
    "    'time_to_nearest_train(min)': 'time_to_nearest_train_station(min)',\n",
    "    'distance_to_nearest_train(km)': 'distance_to_nearest_train_station(km)'\n",
    "}, inplace=True)\n",
    "\n",
    "# Merge the school columns into the property_train dataframe\n",
    "merged_df = pd.concat([property_train_df, school_columns], axis=1)\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_df_path = Path.cwd().parent / 'data' / 'curated'/'rent_with_proximity.csv'\n",
    "merged_df.to_csv(merged_df_path, index=False)\n",
    "\n",
    "print(f\"Merged data with renamed columns saved to {merged_df_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data with rounded values saved to c:\\Users\\29557\\Documents\\GitHub\\project-2-group-real-estate-industry-project-7\\data\\curated\\rent_with_proximity.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the property_school and property_train data\n",
    "property_school_df = pd.read_csv(Path.cwd().parent / 'data' / 'curated' / 'property_school.csv')\n",
    "property_train_df = pd.read_csv(Path.cwd().parent / 'data' / 'curated' / 'property_train.csv')\n",
    "\n",
    "# Extract 'distance_to_nearest_school(km)' and 'time_to_nearest_school(min)' columns from property_school_df\n",
    "school_columns = property_school_df[['distance_to_nearest_school(km)', 'time_to_nearest_school(min)']]\n",
    "\n",
    "# Rename the 'time_to_nearest_train(min)' and 'distance_to_nearest_train(km)' columns in the property_train dataframe\n",
    "property_train_df.rename(columns={\n",
    "    'time_to_nearest_train(min)': 'time_to_nearest_train_station(min)',\n",
    "    'distance_to_nearest_train(km)': 'distance_to_nearest_train_station(km)'\n",
    "}, inplace=True)\n",
    "\n",
    "# Merge the school columns into the property_train dataframe\n",
    "merged_df = pd.concat([property_train_df, school_columns], axis=1)\n",
    "\n",
    "# Round the distance and time columns to 2 decimal places\n",
    "merged_df['distance_to_nearest_school(km)'] = merged_df['distance_to_nearest_school(km)'].round(2)\n",
    "merged_df['time_to_nearest_school(min)'] = merged_df['time_to_nearest_school(min)'].round(2)\n",
    "merged_df['distance_to_nearest_train_station(km)'] = merged_df['distance_to_nearest_train_station(km)'].round(2)\n",
    "merged_df['time_to_nearest_train_station(min)'] = merged_df['time_to_nearest_train_station(min)'].round(2)\n",
    "\n",
    "# Save the final dataframe to a new CSV file\n",
    "merged_df_path = Path.cwd().parent / 'data' / 'curated'/'rent_with_proximity.csv'\n",
    "merged_df.to_csv(merged_df_path, index=False)\n",
    "\n",
    "print(f\"Merged data with rounded values saved to {merged_df_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
